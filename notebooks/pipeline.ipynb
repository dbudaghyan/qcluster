{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation Notebook for the Q-Cluster Pipeline\n",
    "\n",
    "This notebook provides an interactive environment to run, analyze, and experiment with the text clustering pipeline defined in `pipeline.py`. \n",
    "\n",
    "The goal of the pipeline is to:\n",
    "1. Load a dataset of customer support interactions with predefined categories.\n",
    "2. Generate embeddings for the text.\n",
    "3. Use an unsupervised clustering algorithm to group the interactions.\n",
    "4. Use a Large Language Model (LLM) to describe the contents of each cluster.\n",
    "5. Match the generated clusters back to the original predefined categories.\n",
    "6. Evaluate the performance of the clustering.\n",
    "\n",
    "You can use this notebook to easily swap out different algorithms for feature extraction, clustering, and similarity matching to find the best combination for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Before running the pipeline, you need to set up your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install Dependencies\n",
    "\n",
    "First, ensure you have all the required Python libraries installed. You can install them using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Set Environment Variables\n",
    "\n",
    "The pipeline uses environment variables to configure key settings, such as prompt templates and output directories. Create a `.env` file in the root of your project with the following content. The `python-dotenv` library will load these automatically if it's installed.\n",
    "\n",
    "```.env\n",
    "# Path to the directory where evaluation results will be stored\n",
    "EVALUATION_RESULTS_DIR=\"./evaluation_results\"\n",
    "\n",
    "# The prompt template for generating cluster descriptions\n",
    "DESCRIPTION_PROMPT_TEMPLATE=\"description_prompt_from_instructions.txt\"\n",
    "\n",
    "# (Optional) The LLM model to use for generating qualitative reports\n",
    "OLLAMA_REPORTING_MODEL=\"llama2\"\n",
    "```\n",
    "\n",
    "**Note:** Ensure the prompt template file (e.g., `description_prompt_from_instructions.txt`) exists and contains the template you want the LLM to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Prepare the Data\n",
    "\n",
    "The script expects the dataset to be located at `../data/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv`. Make sure you have downloaded the data and placed it in the correct directory relative to your project's `ROOT_DIR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Imports\n",
    "\n",
    "Let's import all the necessary modules and functions from the `qcluster` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from os import PathLike\n",
    "\n",
    "import torch\n",
    "from loguru import logger\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from qcluster import ROOT_DIR\n",
    "from qcluster.algorithms.clustering import kmeans_clustering, hdbscan_clustering\n",
    "from qcluster.llm.describer import get_description\n",
    "from qcluster.algorithms.feature_extractors import create_embeddings, umap_reduction, pca_reduction\n",
    "from qcluster.algorithms.similarity import get_top_n_similar_embeddings\n",
    "from qcluster.custom_types import CategoryType, IdToCategoryResultType, category_to_idx, ClusterType\n",
    "from qcluster.datamodels.instruction import InstructionCollection\n",
    "from qcluster.datamodels.sample import SampleCollection\n",
    "from qcluster.evaluation import evaluate_results, cluster_to_class_similarity_measures, store_results\n",
    "from qcluster.preload import MODEL\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "logger.info(\"Environment variables loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining the Pipeline Components\n",
    "\n",
    "Here, we define the core components of our pipeline. This is where you can experiment by swapping out functions and changing parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Configure Experiment Parameters\n",
    "\n",
    "Choose which algorithms you want to use for this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXPERIMENT HERE ---\n",
    "\n",
    "# 1. Choose a Feature Extractor\n",
    "def feature_extractor_umap(texts: list[str]) -> torch.Tensor:\n",
    "    \"\"\"Creates embeddings and reduces dimensionality with UMAP.\"\"\"\n",
    "    embeddings = create_embeddings(texts, model=MODEL)\n",
    "    embeddings = umap_reduction(embeddings, n_components=28)\n",
    "    return embeddings\n",
    "\n",
    "def feature_extractor_pca(texts: list[str]) -> torch.Tensor:\n",
    "    \"\"\"Creates embeddings and reduces dimensionality with PCA.\"\"\"\n",
    "    embeddings = create_embeddings(texts, model=MODEL)\n",
    "    embeddings = pca_reduction(embeddings, n_components=28)\n",
    "    return embeddings\n",
    "\n",
    "# Set the feature_extractor for this run\n",
    "feature_extractor = feature_extractor_umap \n",
    "logger.info(f\"Using feature extractor: {feature_extractor.__name__}\")\n",
    "\n",
    "# 2. Choose a Clustering Function\n",
    "N_CATEGORIES = len(SampleCollection.all_category_classes()) - 1 # Exclude 'UNKNOWN'\n",
    "\n",
    "clustering_kmeans = functools.partial(kmeans_clustering, n_clusters=N_CATEGORIES)\n",
    "clustering_hdbscan = functools.partial(hdbscan_clustering, min_cluster_size=100)\n",
    "\n",
    "# Set the clustering_function for this run\n",
    "clustering_function = clustering_kmeans\n",
    "logger.info(f\"Using clustering function: {clustering_function.func.__name__}\")\n",
    "\n",
    "\n",
    "# 3. Configure the Similarity Matching Function\n",
    "similarity_function = functools.partial(\n",
    "    get_top_n_similar_embeddings,\n",
    "    use_mmr=False, # Try setting to True\n",
    "    # mmr_lambda=0.3, # Tune this if use_mmr is True\n",
    ")\n",
    "logger.info(f\"Using similarity function with MMR: {similarity_function.keywords.get('use_mmr', False)}\")\n",
    "\n",
    "\n",
    "# 4. Configure the Describer Function\n",
    "describer = functools.partial(\n",
    "    get_description,\n",
    "    template_name=os.environ[\"DESCRIPTION_PROMPT_TEMPLATE\"],\n",
    ")\n",
    "\n",
    "# 5. Define Data Path\n",
    "CSV_PATH = (\n",
    "    ROOT_DIR.parent\n",
    "    / \"data\"\n",
    "    / \"Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running the Pipeline Step-by-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Samples\n",
    "logger.info(f\"Loading samples from {CSV_PATH}...\")\n",
    "samples = SampleCollection.from_csv(CSV_PATH)\n",
    "\n",
    "# Optional: uncomment the line below to run on a smaller subset for faster testing\n",
    "# samples = samples[:1000]\n",
    "\n",
    "logger.info(f\"Loaded {len(samples)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Process Samples (Group them and create embeddings)\n",
    "logger.info(\"Grouping samples by category and updating embeddings...\")\n",
    "samples_by_category = samples.group_by_category()\n",
    "logger.info(f\"Grouped samples into {len(samples_by_category)} categories.\")\n",
    "\n",
    "logger.info(\"Describing samples in each category...\")\n",
    "for category, sample_collection in tqdm(samples_by_category.items()):\n",
    "    sample_collection.update_embeddings(feature_extractor)\n",
    "    sample_collection.describe(describer)\n",
    "logger.info(\"Embeddings updated and samples described.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create Instructions and Cluster them\n",
    "logger.info(\"Creating instruction collection from samples...\")\n",
    "instructions = InstructionCollection.from_samples(samples)\n",
    "logger.info(f\"Created an instruction collection with {len(instructions)} instructions.\")\n",
    "\n",
    "logger.info(\"Updating instruction embeddings and clustering...\")\n",
    "instructions.update_embeddings(feature_extractor)\n",
    "instructions.update_clusters(\n",
    "    clustering_function=clustering_function, \n",
    "    use_raw_instructions=False\n",
    ")\n",
    "logger.info(\"Instruction embeddings updated and clusters created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Get Clusters and Describe Them\n",
    "logger.info(\"Grouping instructions by cluster...\")\n",
    "instructions_by_cluster = instructions.group_by_cluster()\n",
    "logger.info(f\"Grouped instructions into {len(instructions_by_cluster)} clusters.\")\n",
    "\n",
    "logger.info(\"Describing instructions in each cluster...\")\n",
    "for cluster, instruction_collection in tqdm(instructions_by_cluster.items()):\n",
    "    # Skip the noise cluster if it exists (often labeled -1 by density-based algorithms)\n",
    "    if cluster == -1:\n",
    "        continue\n",
    "    instruction_collection.describe(describer)\n",
    "logger.info(\"Instructions described.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Match Clusters to Original Categories\n",
    "logger.info(\"Finding top similar sample categories for each instruction cluster...\")\n",
    "id_to_category_pairs: IdToCategoryResultType = {}\n",
    "for cluster, instruction_collection in tqdm(instructions_by_cluster.items()):\n",
    "    # Skip noise cluster\n",
    "    if cluster == -1:\n",
    "        for sample in instruction_collection:\n",
    "            # Map noise points to an 'UNKNOWN' category or handle as needed\n",
    "            id_to_category_pairs[sample.id] = (samples.get_sample_by_id(sample.id).category, 'NOISE_CLUSTER')\n",
    "        continue\n",
    "\n",
    "    predicted_category = instruction_collection.get_cluster_category(\n",
    "        sample_collections=list(samples_by_category.values()),\n",
    "        similarity_function=similarity_function,\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Cluster N {instruction_collection.cluster} title: `{instruction_collection.title}` -> matched to category: {predicted_category}\"\n",
    "    )\n",
    "    \n",
    "    for sample in instruction_collection:\n",
    "        id_to_category_pairs[sample.id] = (\n",
    "            samples.get_sample_by_id(sample.id).category,\n",
    "            predicted_category,\n",
    "        )\n",
    "logger.info(\"Matching completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate and Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the results\n",
    "logger.info(\"Evaluating results...\")\n",
    "cm = evaluate_results(id_to_category_pairs)\n",
    "\n",
    "predicted_cluster_list = []\n",
    "actual_category_list = []\n",
    "\n",
    "for id_, (actual_category, predicted_category) in id_to_category_pairs.items():\n",
    "    # We can't score noise clusters, so we skip them in the evaluation\n",
    "    if predicted_category == 'NOISE_CLUSTER':\n",
    "        continue\n",
    "    predicted_cluster_list.append(predicted_category)\n",
    "    actual_category_list.append(actual_category)\n",
    "\n",
    "cluster_to_class_scores = cluster_to_class_similarity_measures(\n",
    "    predicted_cluster_list, actual_category_list\n",
    ")\n",
    "\n",
    "logger.info(\"--- Evaluation Results ---\")\n",
    "for measure, score in cluster_to_class_scores.items():\n",
    "    print(f\"{measure.capitalize()}: {score:.4f}\")\n",
    "\n",
    "cm.print_matrix(sparse=True)\n",
    "cm.stat(summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Store the results\n",
    "output_path = Path(os.environ[\"EVALUATION_RESULTS_DIR\"])\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "try:\n",
    "    git_commit = os.popen(\"git rev-parse --short HEAD\").read().strip()\n",
    "except Exception:\n",
    "    git_commit = \"unknown\"\n",
    "\n",
    "unique_folder_name = f\"{timestamp}-{git_commit}-{feature_extractor.__name__}-{clustering_function.func.__name__}\"\n",
    "unique_folder_path = output_path / unique_folder_name\n",
    "\n",
    "logger.info(f\"Storing results in: {unique_folder_path}\")\n",
    "\n",
    "store_results(\n",
    "    cm=cm,\n",
    "    cluster_to_class_scores=cluster_to_class_scores,\n",
    "    storage_path=unique_folder_path,\n",
    "    instructions_by_cluster=instructions_by_cluster,\n",
    ")\n",
    "\n",
    "logger.info(\"Run complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How to Experiment\n",
    "\n",
    "The most important part of this notebook is the configuration cell in **Section 2.1**. By changing the function definitions and assignments in that cell, you can fundamentally alter the pipeline's behavior.\n",
    "\n",
    "### Ideas for Experiments\n",
    "\n",
    "1.  **Clustering Algorithm**: \n",
    "    - Change `clustering_function = clustering_kmeans` to `clustering_function = clustering_hdbscan`.\n",
    "    - Observe the results. HDBSCAN can identify noise and doesn't require a fixed number of clusters. How does this affect your evaluation scores? \n",
    "    - Tune the `min_cluster_size` parameter for HDBSCAN.\n",
    "\n",
    "2.  **Dimensionality Reduction**:\n",
    "    - Change `feature_extractor = feature_extractor_umap` to `feature_extractor = feature_extractor_pca`.\n",
    "    - PCA is a linear technique, while UMAP is non-linear. Does one work better for this specific text data?\n",
    "\n",
    "3.  **Similarity Matching**:\n",
    "    - In the `similarity_function` definition, set `use_mmr=True`.\n",
    "    - Maximal Marginal Relevance (MMR) is designed to promote diversity in the results. Does this help in correctly matching clusters to categories?\n",
    "    - Try tuning the `mmr_lambda` parameter (between 0 and 1). A higher value emphasizes similarity, while a lower value emphasizes diversity.\n",
    "\n",
    "4.  **Prompt Engineering**:\n",
    "    - Create a new prompt template file (e.g., `my_new_prompt.txt`).\n",
    "    - Update the `.env` file to point `DESCRIPTION_PROMPT_TEMPLATE` to your new file.\n",
    "    - See if a different prompt results in better, more coherent cluster descriptions, which might improve the matching process.\n",
    "\n",
    "After each change in **Section 2.1**, you can re-run all the cells from **Section 3** onwards to see the impact of your experiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
