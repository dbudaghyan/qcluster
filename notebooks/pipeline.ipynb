{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Clustering and Analysis Pipeline\n",
    "\n",
    "This notebook walks through a pipeline for clustering text data, specifically customer support training data. The process involves several key stages:\n",
    "\n",
    "1.  **Data Loading**: Load a dataset of customer support interactions from a CSV file.\n",
    "2.  **Feature Extraction**: Convert text into numerical representations (embeddings) and then reduce the dimensionality of these embeddings to make them more suitable for clustering.\n",
    "3.  **Instruction Generation**: Create a set of instructions from the sample data.\n",
    "4.  **Clustering**: Group the generated instructions into clusters based on their semantic similarity.\n",
    "5.  **Cluster Description & Matching**: Generate a descriptive title for each cluster and match it back to the original sample categories.\n",
    "6.  **Evaluation**: Assess the quality of the clustering using a confusion matrix and other similarity scores.\n",
    "\n",
    "Each step is contained in its own cell, with explanations of the code and guidance on how to modify it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "\n",
    "First, we import all the necessary libraries and modules. This includes utilities for data handling, logging, machine learning models, and our custom pipeline functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-14 12:58:46.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqcluster.preload\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mLoading the SentenceTransformer model...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Preloading env vars, seeds and models\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import functools\n",
    "import time\n",
    "from os import PathLike\n",
    "\n",
    "import torch\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "from pycm import ConfusionMatrix\n",
    "\n",
    "from qcluster import tqdm\n",
    "from tqdm import tqdm\n",
    "from qcluster import ROOT_DIR\n",
    "from qcluster.preload import MODEL\n",
    "\n",
    "# Clustering algorithms\n",
    "from qcluster.algorithms.clustering import (\n",
    "    kmeans_clustering,\n",
    "    # dbscan_clustering,\n",
    "    # hdbscan_clustering,\n",
    "    # agglomerative_clustering,\n",
    "    # bert_topic_extraction,\n",
    "    # spectral_clustering\n",
    ")\n",
    "\n",
    "# Feature extractors and dimensionality reduction\n",
    "from qcluster.algorithms.feature_extractors import (\n",
    "    create_embeddings,\n",
    "    # pca_reduction,\n",
    "    umap_reduction,\n",
    "    # pacmap_reduction\n",
    ")\n",
    "\n",
    "# Data models and custom types\n",
    "from qcluster.custom_types import CategoryType, IdToCategoryResultType, category_to_idx\n",
    "from qcluster.datamodels.instruction import InstructionCollection\n",
    "from qcluster.datamodels.sample import SampleCollection\n",
    "\n",
    "# Other pipeline components\n",
    "from qcluster.algorithms.describer import get_description\n",
    "from qcluster.evaluation import evaluate_results, cluster_to_class_similarity_measures\n",
    "from qcluster.algorithms.similarity import get_top_n_similar_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Hyperparameters\n",
    "\n",
    "This section defines the core components of our pipeline and their parameters. By modifying the variables in this cell, you can easily experiment with different algorithms and settings.\n",
    "\n",
    "### How to Modify:\n",
    "-   **`clustering_function`**: To change the clustering algorithm, comment out `kmeans_clustering` and uncomment another option like `hdbscan_clustering`. Adjust the parameters accordingly. For instance, K-Means requires `n_clusters`, while HDBSCAN uses `min_cluster_size`.\n",
    "-   **`feature_extractor`**: To change the dimensionality reduction technique, replace `umap_reduction` with another imported function like `pca_reduction` or `pacmap_reduction`. You can also adjust the `n_components` parameter, which determines the final number of dimensions for the embeddings.\n",
    "-   **`similarity_function`**: You can toggle `use_mmr` (Maximal Marginal Relevance) to control the diversity of similarity search results. When `use_mmr=True`, you can also tune the `mmr_lambda` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-14 12:58:52.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mFound 12 unique categories.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Path to the dataset\n",
    "CSV_PATH: PathLike = (\n",
    "        ROOT_DIR.parent\n",
    "        / \"data\"\n",
    "        / \"Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\"\n",
    ")\n",
    "\n",
    "# Dynamically determine the number of categories from the data\n",
    "N_CATEGORIES = len(SampleCollection.all_category_classes())\n",
    "logger.info(f\"Found {N_CATEGORIES} unique categories.\")\n",
    "\n",
    "# --- Clustering Algorithm Configuration ---\n",
    "clustering_function = functools.partial(\n",
    "    kmeans_clustering,\n",
    "    n_clusters=N_CATEGORIES\n",
    "    # --- Alternative: HDBSCAN ---\n",
    "    # hdbscan_clustering,\n",
    "    # min_cluster_size=15, # Minimum size for a group to be considered a cluster\n",
    ")\n",
    "\n",
    "# --- Cluster Describer Configuration ---\n",
    "describer = functools.partial(\n",
    "    get_description,\n",
    "    template_name='description_prompt_simple',\n",
    "    # --- Alternative: More detailed template ---\n",
    "    # template_name='description_prompt_from_instructions'\n",
    ")\n",
    "\n",
    "# --- Similarity Function Configuration ---\n",
    "similarity_function = functools.partial(\n",
    "    get_top_n_similar_embeddings,\n",
    "    use_mmr=False,\n",
    "    # --- MMR Parameters (for diversifying results) ---\n",
    "    # mmr_lambda=0.3, # Set between 0 (focus on similarity) and 1 (focus on diversity)\n",
    "    # mmr_top_n=20\n",
    ")\n",
    "\n",
    "# --- Feature Extraction Pipeline ---\n",
    "def feature_extractor(texts: list[str]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Creates embeddings for the given texts and reduces their dimensionality.\n",
    "    \"\"\"\n",
    "    # Step 1: Create high-dimensional embeddings from text\n",
    "    embeddings = create_embeddings(texts, model=MODEL)\n",
    "    \n",
    "    # Step 2: Reduce dimensionality\n",
    "    # Recommended to use a value between 5 and 50 for n_components\n",
    "    reduced_embeddings = umap_reduction(embeddings, n_components=28)\n",
    "    return reduced_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline Functions\n",
    "\n",
    "Here we define the functions that encapsulate each major step of the pipeline, from loading data to evaluating the final results. This modular approach makes the process easy to follow and debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples(path: PathLike) -> SampleCollection:\n",
    "    \"\"\"Loads samples from a CSV file.\"\"\"\n",
    "    logger.info(f\"Loading samples from {path}...\")\n",
    "    samples = SampleCollection.from_csv(path)\n",
    "    logger.info(f\"Loaded {len(samples)} samples.\")\n",
    "    return samples\n",
    "\n",
    "def process_samples(samples: SampleCollection) -> dict[CategoryType, SampleCollection]:\n",
    "    \"\"\"Groups samples by category and updates their embeddings and descriptions.\"\"\"\n",
    "    logger.info(\"Grouping samples by category and updating embeddings...\")\n",
    "    samples_by_category = samples.group_by_category()\n",
    "    logger.info(f\"Grouped samples into {len(samples_by_category)} categories.\")\n",
    "\n",
    "    logger.info(\"Describing samples in each category...\")\n",
    "    for category, sample_collection in tqdm(samples_by_category.items()):\n",
    "        sample_collection.update_embeddings(feature_extractor)\n",
    "        sample_collection.describe(describer)\n",
    "    logger.info(\"Embeddings updated and samples described.\")\n",
    "    return samples_by_category\n",
    "\n",
    "def create_instructions(samples: SampleCollection) -> InstructionCollection:\n",
    "    \"\"\"Creates and processes an InstructionCollection from a SampleCollection.\"\"\"\n",
    "    logger.info(\"Creating instruction collection from samples...\")\n",
    "    instructions = InstructionCollection.from_samples(samples)\n",
    "    logger.info(f\"Created an instruction collection with {len(instructions)} instructions.\")\n",
    "\n",
    "    logger.info(\"Updating instruction embeddings and clustering...\")\n",
    "    (\n",
    "        instructions\n",
    "        .update_embeddings(feature_extractor)\n",
    "        .update_clusters(clustering_function=clustering_function, use_raw_instructions=False)\n",
    "    )\n",
    "    logger.info(\"Instruction embeddings updated and clusters created.\")\n",
    "    return instructions\n",
    "\n",
    "def create_and_match_clusters(\n",
    "        instructions: InstructionCollection,\n",
    "        samples_by_category: dict[CategoryType, SampleCollection],\n",
    "        all_samples: SampleCollection\n",
    ") -> IdToCategoryResultType:\n",
    "    \"\"\"Describes instructions and matches them to sample categories.\"\"\"\n",
    "    logger.info(\"Grouping instructions by cluster...\")\n",
    "    instructions_by_cluster = instructions.group_by_cluster()\n",
    "    logger.info(f\"Grouped instructions into {len(instructions_by_cluster)} clusters.\")\n",
    "\n",
    "    logger.info(\"Describing instructions in each cluster...\")\n",
    "    for cluster, instruction_collection in tqdm(instructions_by_cluster.items()):\n",
    "        instruction_collection.describe(describer)\n",
    "    logger.info(\"Instructions described.\")\n",
    "\n",
    "    logger.info(\"Finding top similar sample categories for each instruction cluster...\")\n",
    "    id_to_category_pairs: IdToCategoryResultType = {}\n",
    "    for cluster, instruction_collection in tqdm(instructions_by_cluster.items()):\n",
    "        predicted_category = instruction_collection.get_cluster_category(\n",
    "            sample_collections=list(samples_by_category.values()),\n",
    "            similarity_function=similarity_function,\n",
    "        )\n",
    "        logger.info(f\"Cluster N {instruction_collection.cluster} title: `{instruction_collection.title}` top similar sample category: {predicted_category}\")\n",
    "        logger.info(f\"Mapping cluster {cluster} to category {predicted_category}\")\n",
    "        for sample in instruction_collection:\n",
    "            id_to_category_pairs[sample.id] = (\n",
    "                all_samples.get_sample_by_id(sample.id).category,\n",
    "                predicted_category\n",
    "            )\n",
    "    logger.info(\"Matching completed.\")\n",
    "    logger.info(f\"Total pairs: {len(id_to_category_pairs)}\")\n",
    "    return id_to_category_pairs\n",
    "\n",
    "def store_results(cm: ConfusionMatrix, cluster_to_class_scores, storage_path: PathLike):\n",
    "    \"\"\"Saves the confusion matrix and scores to CSV files.\"\"\"\n",
    "    storage_path = Path(storage_path)\n",
    "    os.makedirs(os.path.dirname(storage_path), exist_ok=True)\n",
    "    logger.info(f\"Storing evaluation results to {storage_path}...\")\n",
    "    cm.save_csv(storage_path / \"confusion_matrix.csv\")\n",
    "    # Note: Storing cluster_to_class_scores would require converting the dict to a file format like json or csv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execute the Pipeline\n",
    "\n",
    "This is the main execution block. It calls the pipeline functions in sequence and prints the final evaluation metrics. \n",
    "\n",
    "### Note on Subsetting Data:\n",
    "To run the pipeline on a smaller portion of the data for faster testing, you can uncomment the line `samples: SampleCollection = samples[:1000]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-14 12:58:52.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_samples\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mLoading samples from /Users/davidbudaghyan/dev/lab/customer_question_clustering/data/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv...\u001b[0m\n",
      "\u001b[32m2025-06-14 12:58:53.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_samples\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mLoaded 26872 samples.\u001b[0m\n",
      "\u001b[32m2025-06-14 12:58:53.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mUsing 26872 samples for processing.\u001b[0m\n",
      "\u001b[32m2025-06-14 12:58:53.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_samples\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mGrouping samples by category and updating embeddings...\u001b[0m\n",
      "\u001b[32m2025-06-14 12:58:53.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_samples\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mGrouped samples into 11 categories.\u001b[0m\n",
      "\u001b[32m2025-06-14 12:58:53.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_samples\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mDescribing samples in each category...\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [01:35<00:00,  8.65s/it]\n",
      "\u001b[32m2025-06-14 13:00:28.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_samples\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mEmbeddings updated and samples described.\u001b[0m\n",
      "\u001b[32m2025-06-14 13:00:28.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_instructions\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCreating instruction collection from samples...\u001b[0m\n",
      "\u001b[32m2025-06-14 13:00:28.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_instructions\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mCreated an instruction collection with 26872 instructions.\u001b[0m\n",
      "\u001b[32m2025-06-14 13:00:28.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_instructions\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mUpdating instruction embeddings and clustering...\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:13.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_instructions\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mInstruction embeddings updated and clusters created.\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:13.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mGrouping instructions by cluster...\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:13.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mGrouped instructions into 12 clusters.\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:13.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mDescribing instructions in each cluster...\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:21<00:00,  1.80s/it]\n",
      "\u001b[32m2025-06-14 13:01:34.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mInstructions described.\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:34.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mFinding top similar sample categories for each instruction cluster...\u001b[0m\n",
      "  0%|                                                                                                                                                    | 0/12 [00:00<?, ?it/s]\u001b[32m2025-06-14 13:01:35.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 6 title: `Customer Service Interaction Requests` top similar sample category: CONTACT\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:35.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 6 to category CONTACT\u001b[0m\n",
      "  8%|███████████▋                                                                                                                                | 1/12 [00:00<00:06,  1.80it/s]\u001b[32m2025-06-14 13:01:35.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 2 title: `Bill Retrieval and Download Requests` top similar sample category: INVOICE\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:35.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 2 to category INVOICE\u001b[0m\n",
      " 17%|███████████████████████▎                                                                                                                    | 2/12 [00:00<00:04,  2.17it/s]\u001b[32m2025-06-14 13:01:35.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 4 title: `Questions Related to Informing Payment Issues` top similar sample category: PAYMENT\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:35.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 4 to category PAYMENT\u001b[0m\n",
      " 25%|███████████████████████████████████                                                                                                         | 3/12 [00:01<00:03,  2.49it/s]\u001b[32m2025-06-14 13:01:36.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 9 title: `Identifying and Listing Payment Options` top similar sample category: PAYMENT\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:36.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 9 to category PAYMENT\u001b[0m\n",
      " 33%|██████████████████████████████████████████████▋                                                                                             | 4/12 [00:01<00:02,  2.78it/s]\u001b[32m2025-06-14 13:01:36.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 0 title: `Newsletter Subscription and Unsubscription Queries` top similar sample category: SUBSCRIPTION\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:36.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 0 to category SUBSCRIPTION\u001b[0m\n",
      " 42%|██████████████████████████████████████████████████████████▎                                                                                 | 5/12 [00:01<00:02,  2.96it/s]\u001b[32m2025-06-14 13:01:36.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 8 title: `Understanding and Requesting Fee Information` top similar sample category: CANCEL\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:36.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 8 to category CANCEL\u001b[0m\n",
      " 50%|██████████████████████████████████████████████████████████████████████                                                                      | 6/12 [00:02<00:01,  3.10it/s]\u001b[32m2025-06-14 13:01:37.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 7 title: `User Account and Sign-Up Issues` top similar sample category: ACCOUNT\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:37.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 7 to category ACCOUNT\u001b[0m\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████▋                                                          | 7/12 [00:03<00:02,  1.71it/s]\u001b[32m2025-06-14 13:01:38.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 3 title: `Cases and Processes for Requesting Refunds, Reimbursements, and Consumer Claims` top similar sample category: REFUND\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:38.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 3 to category REFUND\u001b[0m\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 8/12 [00:03<00:02,  1.62it/s]\u001b[32m2025-06-14 13:01:38.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 11 title: `Questions Related to Order Status and Delivery Tracking` top similar sample category: DELIVERY\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:38.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 11 to category DELIVERY\u001b[0m\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                   | 9/12 [00:04<00:01,  1.78it/s]\u001b[32m2025-06-14 13:01:39.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 5 title: `Address Submission and Modification Issues` top similar sample category: SHIPPING\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:39.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 5 to category SHIPPING\u001b[0m\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 10/12 [00:04<00:01,  1.91it/s]\u001b[32m2025-06-14 13:01:39.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 10 title: `User Refund and Shipping Options Queries` top similar sample category: REFUND\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:39.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 10 to category REFUND\u001b[0m\n",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 11/12 [00:05<00:00,  1.91it/s]\u001b[32m2025-06-14 13:01:40.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCluster N 1 title: `Customer Order and Purchase Assistance Requests` top similar sample category: ORDER\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:40.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mMapping cluster 1 to category ORDER\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:05<00:00,  2.08it/s]\n",
      "\u001b[32m2025-06-14 13:01:40.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mMatching completed.\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:40.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_and_match_clusters\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mTotal pairs: 26872\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:40.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mEvaluating results...\u001b[0m\n",
      "\u001b[32m2025-06-14 13:01:40.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mEvaluation results:\u001b[0m\n",
      "/Users/davidbudaghyan/dev/lab/customer_question_clustering/.venv/lib/python3.12/site-packages/pycm/cm.py:136: RuntimeWarning:\n",
      "\n",
      "Confusion matrix is high-dimensional and may not display properly. Consider using the `sparse` flag in printing functions, or save it as a CSV file for better visualization.\n",
      "\n",
      "/Users/davidbudaghyan/dev/lab/customer_question_clustering/.venv/lib/python3.12/site-packages/pycm/cm.py:204: RuntimeWarning:\n",
      "\n",
      "Confusion matrix is high-dimensional and may not display properly. Consider using the `sparse` flag in printing functions, or save it as a CSV file for better visualization.\n",
      "\n",
      "\u001b[32m2025-06-14 13:01:40.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mExecution time: 168.02 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.7451\n",
      "Completeness: 0.6929\n",
      "V_measure: 0.7180\n",
      "Ari: 0.5071\n",
      "Predict            ACCOUNT            CANCEL             CONTACT            DELIVERY           INVOICE            ORDER              PAYMENT            REFUND             SHIPPING           SUBSCRIPTION       \n",
      "Actual\n",
      "ACCOUNT            4542               0                  35                 0                  0                  10                 289                1110               0                  0                  \n",
      "\n",
      "CANCEL             0                  950                0                  0                  0                  0                  0                  0                  0                  0                  \n",
      "\n",
      "CONTACT            1                  0                  1997               0                  0                  0                  0                  0                  1                  0                  \n",
      "\n",
      "DELIVERY           244                32                 13                 1003               6                  30                 8                  642                0                  16                 \n",
      "\n",
      "FEEDBACK           991                0                  1                  1                  0                  0                  0                  1003               0                  1                  \n",
      "\n",
      "INVOICE            0                  0                  0                  0                  1999               0                  0                  0                  0                  0                  \n",
      "\n",
      "ORDER              86                 0                  7                  900                0                  1928               6                  1055               0                  6                  \n",
      "\n",
      "PAYMENT            0                  0                  0                  0                  0                  0                  1996               1                  1                  0                  \n",
      "\n",
      "REFUND             420                5                  0                  0                  0                  0                  38                 2483               21                 25                 \n",
      "\n",
      "SHIPPING           0                  0                  0                  0                  0                  0                  0                  0                  1970               0                  \n",
      "\n",
      "SUBSCRIPTION       0                  0                  0                  0                  0                  0                  0                  0                  0                  999                \n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "ACC Macro                                                         0.9526\n",
      "F1 Macro                                                          0.75399\n",
      "FPR Macro                                                         0.0274\n",
      "Kappa                                                             0.70371\n",
      "NPV Macro                                                         0.97348\n",
      "Overall ACC                                                       0.73932\n",
      "PPV Macro                                                         None\n",
      "SOA1(Landis & Koch)                                               Substantial\n",
      "TPR Macro                                                         0.77937\n",
      "Zero-one Loss                                                     7005\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           ACCOUNT          CANCEL           CONTACT          DELIVERY         FEEDBACK         INVOICE          ORDER            PAYMENT          REFUND           SHIPPING         SUBSCRIPTION     \n",
      "ACC(Accuracy)                                                     0.88144          0.99862          0.99784          0.92959          0.92568          0.99978          0.92185          0.98724          0.83924          0.99914          0.99821          \n",
      "AUC(Area under the ROC curve)                                     0.83768          0.99929          0.99837          0.7334           0.5              0.99988          0.74085          0.99264          0.83515          0.99954          0.99907          \n",
      "AUCI(AUC value interpretation)                                    Very Good        Excellent        Excellent        Good             Poor             Excellent        Good             Excellent        Very Good        Excellent        Excellent        \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.74034          0.9809           0.98569          0.51462          0.0              0.9985           0.64741          0.92088          0.53478          0.9942           0.97654          \n",
      "FN(False negative/miss/type 2 error)                              1444             0                2                991              1997             0                2060             2                509              0                0                \n",
      "FP(False positive/type 1 error/false alarm)                       1742             37               56               901              0                6                40               341              3811             23               48               \n",
      "FPR(Fall-out or false positive rate)                              0.08341          0.00143          0.00225          0.03622          0.0              0.00024          0.00175          0.01371          0.15959          0.00092          0.00186          \n",
      "N(Condition negative)                                             20886            25922            24873            24878            24875            24873            22884            24874            23880            24902            25873            \n",
      "P(Condition positive or support)                                  5986             950              1999             1994             1997             1999             3988             1998             2992             1970             999              \n",
      "POP(Population)                                                   26872            26872            26872            26872            26872            26872            26872            26872            26872            26872            26872            \n",
      "PPV(Precision or positive predictive value)                       0.72279          0.96251          0.97272          0.52679          None             0.99701          0.97967          0.85409          0.3945           0.98846          0.95415          \n",
      "TN(True negative/correct rejection)                               19144            25885            24817            23977            24875            24867            22844            24533            20069            24879            25825            \n",
      "TON(Test outcome negative)                                        20588            25885            24819            24968            26872            24867            24904            24535            20578            24879            25825            \n",
      "TOP(Test outcome positive)                                        6284             987              2053             1904             0                2005             1968             2337             6294             1993             1047             \n",
      "TP(True positive/hit)                                             4542             950              1997             1003             0                1999             1928             1996             2483             1970             999              \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         0.75877          1.0              0.999            0.50301          0.0              1.0              0.48345          0.999            0.82988          1.0              1.0              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the clustering pipeline.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Step 1: Load Data ---\n",
    "    samples = load_samples(CSV_PATH)\n",
    "    \n",
    "    # --- Optional: Uncomment to use a smaller subset of data for quick tests ---\n",
    "    # samples: SampleCollection = samples[:1000]\n",
    "    logger.info(f\"Using {len(samples)} samples for processing.\")\n",
    "\n",
    "    # --- Step 2: Process Samples ---\n",
    "    samples_by_category = process_samples(samples)\n",
    "    \n",
    "    # --- Step 3: Create Instructions and Cluster Them ---\n",
    "    instructions = create_instructions(samples)\n",
    "    \n",
    "    # --- Step 4: Match Clusters to Categories ---\n",
    "    id_to_category_pairs = create_and_match_clusters(\n",
    "        instructions, samples_by_category, samples\n",
    "    )\n",
    "\n",
    "    # --- Step 5: Evaluate Results ---\n",
    "    logger.info(\"Evaluating results...\")\n",
    "    cm = evaluate_results(id_to_category_pairs)\n",
    "    \n",
    "    # Prepare data for similarity score calculation\n",
    "    predicted_cluster_list = []\n",
    "    actual_category_list = []\n",
    "    for id_, (actual_category, predicted_category) in id_to_category_pairs.items():\n",
    "        predicted_cluster_list.append(predicted_category)\n",
    "        actual_category_list.append(actual_category)\n",
    "        \n",
    "    # Calculate and print clustering quality scores\n",
    "    cluster_to_class_scores = cluster_to_class_similarity_measures(\n",
    "        predicted_cluster_list, actual_category_list\n",
    "    )\n",
    "    # Print the confusion matrix and detailed statistics\n",
    "    logger.info(\"Evaluation results:\")\n",
    "    for measure, score in cluster_to_class_scores.items():\n",
    "        print(f\"{measure.capitalize()}: {score:.4f}\")\n",
    "    cm.print_matrix(sparse=True)\n",
    "    cm.stat(summary=True)\n",
    "        store_results(\n",
    "        cm,\n",
    "        cluster_to_class_scores,\n",
    "        storage_path=Path(os.environ[\"EVALUATION_RESULTS_DIR\"])\n",
    "                     / f\"results_{unique_folder_name}\"\n",
    "    )\n",
    "    logger.info(f\"Execution time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
